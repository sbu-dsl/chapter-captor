[01_Extract_headers_from_HTML]

book_list = file_location_with_one_book_id_per_line
html_dir = directory_location_with_books_in_html_format
extracted_header_dir = directory_location_to_store_extracted_headers
num_procs = number_of_processes_to_use_for_parallelization
log_file = location_to_store_status_results


[02_Generate_training_sequences]

train_books_list = file_location_with_one_train_book_id_per_line
text_files_dir = directory_location_with_books_in_txt_gz_format
generated_sequence_dir = directory_location_to_store_generated_sequences
seq_len = length_of_sequences_to_generate_(we_use_120_in_the_paper)
num_procs = number_of_processes_to_use_for_parallelization
log_file = location_to_store_status_results

[03_Train_model]

checkpoint_dir = directory_location_to_store_model_checkpoints
num_epochs = number_of_epochs_to_train_for

[04_Generate_test_probs]

test_books_list = file_location_with_one_test_book_id_per_line
base_xml_files_dir = directory_location_with_books_in_tagged_format
prob_dir = directory_location_to_store_predicted_probabilities
log_file = location_to_store_status_results

[05_Annotate_headers]

output_xml_dir = location_to_store_annotated_xmls
output_pickle_dir = location_to_store_stagewise_results
num_procs = number_of_processes_to_use_for_parallelization
log_file = location_to_store_status_results